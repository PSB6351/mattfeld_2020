{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# You first need to set you directory structure\n",
    "# and collect the behavioral files for the localizer and the\n",
    "# study task separately.  Given that each task will be modeled\n",
    "# separately treat them separately.\n",
    "proj_dir = '/home/mrive301/psb6351_data'\n",
    "behav_dir = os.path.join(proj_dir, 'dset', 'sub-021', 'func')\n",
    "loc_behav_files = sorted(glob(behav_dir + '/*loc*.tsv'))\n",
    "study_behav_files = sorted(glob(behav_dir + '/*study*.tsv'))\n",
    "\n",
    "# In this cell I'm going to first work on the localizer task\n",
    "\n",
    "# Here I am setting up empty dictionary variables that I will\n",
    "# then fill with keys for the different runs which are saved\n",
    "# as separate behavioral tab delimited text files\n",
    "loc_scene_onset_times = {}\n",
    "loc_face_onset_times = {}\n",
    "\n",
    "# Here I am iterating over my text files for the localizer task.\n",
    "# The variable curr_behav_file will be a string variable with\n",
    "# the full path to the separate runs of the localizer task. idx is a counter\n",
    "# used for indexing.\n",
    "for idx, curr_behav_file in enumerate(loc_behav_files):\n",
    "    # Here I am creating my run keys.  idx is 0 based so I am adding a 1.\n",
    "    # The variables associated with each key are empty lists.\n",
    "    loc_scene_onset_times[f'run{idx+1}'] = []\n",
    "    loc_face_onset_times[f'run{idx+1}'] = []\n",
    "    \n",
    "    # I'm using the pandas function read_csv to read in the log files\n",
    "    curr_behav_data = pd.read_csv(curr_behav_file, sep='\\t')\n",
    "    \n",
    "    # I'm creating a temp face and scence onset list variable here because\n",
    "    # the localizer is a block design task.  I want to convolve a hemodynamic\n",
    "    # signal over the entire face and scene periods and not separately for\n",
    "    # each stimulus thus I want to accumulate to onset times for each face/scene\n",
    "    # image presentation and then grab the first.\n",
    "    tmp_face_onset = []\n",
    "    tmp_scene_onset = []\n",
    "    # iterating over trial_type here...i is counter for indexing\n",
    "    for i, curr_trial_type in enumerate(curr_behav_data['trial_type']):\n",
    "        if curr_trial_type == 'face':\n",
    "            # Here I am appending the onset of the stimulus if the current\n",
    "            # trial type is a face.\n",
    "            tmp_face_onset.append(curr_behav_data['onset'][i])\n",
    "        elif curr_trial_type == 'scence': #note...scence was misspelled originally\n",
    "            # Here I am appending the onset of the stimulus if the current\n",
    "            # trial type is a scene.\n",
    "            tmp_scene_onset.append(curr_behav_data['onset'][i])\n",
    "        # here I am using the first trial type when it becomes math and the \n",
    "        # face onset list variable is 20 elements long (just exited a face block)\n",
    "        # to assign the first element of the tmp_face_onset list variable to the \n",
    "        # dictionary that I created earlier.\n",
    "        elif curr_trial_type == 'math' and len(tmp_face_onset) == 20:\n",
    "            loc_face_onset_times[f'run{idx+1}'].append(tmp_face_onset[0])\n",
    "            tmp_face_onset = []\n",
    "        elif curr_trial_type == 'math' and len(tmp_scene_onset) == 20:\n",
    "            loc_scene_onset_times[f'run{idx+1}'].append(tmp_scene_onset[0])\n",
    "            tmp_scene_onset = []\n",
    "            \n",
    "# The following code creates a string element that has the square brackets\n",
    "# removed.  This is important for the following steps below.\n",
    "loc_scene_run1_data = \", \".join(map(str, loc_scene_onset_times['run1']))\n",
    "loc_scene_run2_data = \", \".join(map(str, loc_scene_onset_times['run2']))\n",
    "loc_face_run1_data = \", \".join(map(str, loc_face_onset_times['run1']))\n",
    "loc_face_run2_data = \", \".join(map(str, loc_face_onset_times['run2']))\n",
    "\n",
    "# Here I am defining the sink directory where I would like to save the timing files\n",
    "evs_sink_dir = os.path.join(proj_dir, 'derivatives', 'first_lvl', 'sub-021', 'evs')\n",
    "# I check to see if the directory exists.  If it doesn't I create it.\n",
    "if not os.path.isdir(evs_sink_dir):\n",
    "    os.makedirs(evs_sink_dir)\n",
    "    \n",
    "# below I am defining the file names for the localizer (loc) face and scene evs.\n",
    "# each run is captured on a separate line with the multiple onsets within a run\n",
    "# captured on a single line\n",
    "loc_scene_evs_file = 'loc_scene_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, loc_scene_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{loc_scene_run1_data}\\n'])\n",
    "    fp.writelines([f'{loc_scene_run2_data}\\n'])\n",
    "loc_face_evs_file = 'loc_face_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, loc_face_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{loc_face_run1_data}\\n'])\n",
    "    fp.writelines([f'{loc_face_run2_data}\\n'])\n",
    "\n",
    "# Similar to above I am creating empty dictionary variables\n",
    "# for each of the events that I am interested in.\n",
    "# I will then insert run keys to separate the timing files \n",
    "# for the events of interest and their specific runs.\n",
    "task_fixb4_c_cond_onset_times = {}\n",
    "task_fixb4_ic_cond_onset_times = {}\n",
    "task_remain_events_onset_times = {}\n",
    "task_fixb4_bl_onset_times = {}\n",
    "\n",
    "# Here I am iterating over the study behavior files.  There should be\n",
    "# 4 of them.\n",
    "for idx, curr_behav_file in enumerate(study_behav_files):\n",
    "    # I set the run key for each condition of interest\n",
    "    task_fixb4_c_cond_onset_times[f'run{idx+1}'] = []\n",
    "    task_fixb4_ic_cond_onset_times[f'run{idx+1}'] = []\n",
    "    task_remain_events_onset_times[f'run{idx+1}'] = []\n",
    "    task_fixb4_bl_onset_times[f'run{idx+1}'] = []\n",
    "    \n",
    "    # I read in the current study run behavioral file\n",
    "    curr_behav_data = pd.read_csv(curr_behav_file, sep='\\t')\n",
    "    \n",
    "    # I iterate now over the contents of the run specific data.\n",
    "    # I am specifically iterating over trial_type\n",
    "    for i, curr_trial_type in enumerate(curr_behav_data['trial_type']):\n",
    "        # I am evaluating whether or not the current trail type was a \n",
    "        # fixed association that had a conditional trial that followed with a face\n",
    "        # or a scene\n",
    "        if 'face' in curr_trial_type or 'scene' in curr_trial_type:\n",
    "            # if it was either of those grab that onset\n",
    "            tmp_fix_onset = curr_behav_data['onset'][i]\n",
    "            # if this is not our first trial (i = counter > 0) - remember python is 0-based\n",
    "            if i > 0:\n",
    "                # evaluate whether or not the LAST TRIAL (i-1) was a scene or face fix trial\n",
    "                # grab the current onset time and assign it to the remaining events.\n",
    "                # In the analysis that I am interested in pursuing I want to separate these\n",
    "                # trials from trials where the fix face and scence trials are followed either\n",
    "                # by a conditional trial or by a baseline trial\n",
    "                # I THINK THERE IS A BUG HERE...SEEMING TO ONLY ASSIGN THESE AT THE END OF RUNS\n",
    "                # DEBUG PLEASE\n",
    "                    #Vanessa's answer: I think the reason these are only assigned at the end of runs is because\n",
    "                    #at the end of every run (got info from the event.tsv file) a face or scene are preceded by\n",
    "                    #another face or scene. \n",
    "                if 'face' in curr_behav_data['trial_type'][i-1] or 'scene' in curr_behav_data['trial_type'][i-1]:\n",
    "                    task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "        # Here I am evaluating whether or not the current trial type is a conditional trial \n",
    "        # that was responded to correctly\n",
    "        elif curr_trial_type == 'COND' and curr_behav_data['acc'][i] == 1.0:\n",
    "            # I am then evaluating wheter or not the LAST TRIAL (i - 1)...was a fix scence or face\n",
    "            # trial and then appending that temp onset to fill in  \n",
    "            if 'face' in curr_behav_data['trial_type'][i-1] or 'scene' in curr_behav_data['trial_type'][i-1]:\n",
    "                task_fixb4_c_cond_onset_times[f'run{idx+1}'].append(tmp_fix_onset)\n",
    "            else:\n",
    "                task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "        # I do the same for conditional trials that were incorrect.  Trying to separate\n",
    "        # fix trials that preceded correct from incorrect conditional trials\n",
    "        elif curr_trial_type == 'COND' and curr_behav_data['acc'][i] == 0.0:\n",
    "            if 'face' in curr_behav_data['trial_type'][i-1] or 'scene' in curr_behav_data['trial_type'][i-1]:\n",
    "                task_fixb4_ic_cond_onset_times[f'run{idx+1}'].append(tmp_fix_onset)\n",
    "            else:\n",
    "                task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "        # Now I am doing the same thing for trials that precede the perceptual baseline trials\n",
    "        # These trials will be used for the MVPA anlaysis that is planned.\n",
    "        # TO DO:  NEED TO SEPARATE THESE FOR SCENCE AND FACE RATHER THAN COMBINE\n",
    "            #Vanessa's answer: separated by face and scene and then added the remaining events \n",
    "        elif curr_trial_type == 'baseline':\n",
    "            if 'face' in curr_behav_data['trial_type'][i-1]:\n",
    "                task_fixb4_bl_onset_times[f'run{idx+1}'].append(tmp_fix_onset)\n",
    "            else:\n",
    "                task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "            if 'scene' in curr_behav_data['trial_type'][i-1]:\n",
    "                task_fixb4_bl_onset_times[f'run{idx+1}'].append(tmp_fix_onset)\n",
    "            else:\n",
    "                task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "        # Here I am trying to assign conditional trial onsets to the remaining events regressor\n",
    "        # BUG HERE...THE TIMING OF THESE SHOULD BE PEPPERED THROUGHOUT THE RUNS MORE EVENLY.\n",
    "        # DEBUG PLEASE.\n",
    "                #Vanessa's answer: Since the \"remaining events\" conditional statement was not evaluated for whether\n",
    "                #the last trial was a fixed scene or face, it probably means this conditional statement has to be \n",
    "                # added to every condition of interest (i.e., baseline and the two task trials (face and scene)). \n",
    "                #Also, based on the way this chunk of code is set up, if the run does not meet any of the face or scene or\n",
    "                #baseline criteria, then we can't just disregard that run, we have to add it to the \"remainig events\"\n",
    "                #directionary created earlier in this code.\n",
    "        #elif curr_trial_type == 'COND':\n",
    "            #task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "# Given that we're setting things up to analyze in AFNI\n",
    "# you can't have runs that don't have any events in them....or\n",
    "# you can but you can't have an empty row...thus here I am checking\n",
    "# to see if the runs are empty and if they are adding a filler (-1)\n",
    "for curr_run in ['run1', 'run2', 'run3', 'run4']:\n",
    "    if len(task_fixb4_c_cond_onset_times[curr_run]) == 0:\n",
    "        task_fixb4_c_cond_onset_times[curr_run].append(-1)\n",
    "    if len(task_fixb4_ic_cond_onset_times[curr_run]) == 0:\n",
    "        task_fixb4_ic_cond_onset_times[curr_run].append(-1)\n",
    "    if len(task_remain_events_onset_times[curr_run]) == 0:\n",
    "        task_remain_events_onset_times[curr_run].append(-1)\n",
    "    if len(task_fixb4_bl_onset_times[curr_run]) == 0:\n",
    "        task_fixb4_bl_onset_times[curr_run].append(-1)\n",
    "\n",
    "# Reformatting as before to save as a text file with no square brackets\n",
    "task_fixb4_c_cond_r1 = \", \".join(map(str, task_fixb4_c_cond_onset_times['run1']))\n",
    "task_fixb4_c_cond_r2 = \", \".join(map(str, task_fixb4_c_cond_onset_times['run2']))\n",
    "task_fixb4_c_cond_r3 = \", \".join(map(str, task_fixb4_c_cond_onset_times['run3']))\n",
    "task_fixb4_c_cond_r4 = \", \".join(map(str, task_fixb4_c_cond_onset_times['run4']))\n",
    "\n",
    "task_fixb4_ic_cond_r1 = \", \".join(map(str, task_fixb4_ic_cond_onset_times['run1']))\n",
    "task_fixb4_ic_cond_r2 = \", \".join(map(str, task_fixb4_ic_cond_onset_times['run2']))\n",
    "task_fixb4_ic_cond_r3 = \", \".join(map(str, task_fixb4_ic_cond_onset_times['run3']))\n",
    "task_fixb4_ic_cond_r4 = \", \".join(map(str, task_fixb4_ic_cond_onset_times['run4']))\n",
    "\n",
    "task_remain_evs_cond_r1 = \", \".join(map(str, task_remain_events_onset_times['run1']))\n",
    "task_remain_evs_cond_r2 = \", \".join(map(str, task_remain_events_onset_times['run2']))\n",
    "task_remain_evs_cond_r3 = \", \".join(map(str, task_remain_events_onset_times['run3']))\n",
    "task_remain_evs_cond_r4 = \", \".join(map(str, task_remain_events_onset_times['run4']))\n",
    "\n",
    "task_fixb4_bl_cond_r1 = \", \".join(map(str, task_fixb4_bl_onset_times['run1']))\n",
    "task_fixb4_bl_cond_r2 = \", \".join(map(str, task_fixb4_bl_onset_times['run2']))\n",
    "task_fixb4_bl_cond_r3 = \", \".join(map(str, task_fixb4_bl_onset_times['run3']))\n",
    "task_fixb4_bl_cond_r4 = \", \".join(map(str, task_fixb4_bl_onset_times['run4']))\n",
    "\n",
    "# Creating and checking to see if the directory exists\n",
    "evs_sink_dir = os.path.join(proj_dir, 'derivatives', 'first_lvl', 'sub-021', 'evs')\n",
    "if not os.path.isdir(evs_sink_dir):\n",
    "    os.makedirs(evs_sink_dir)\n",
    "\n",
    "# creating my separate ev files with runs written to each line\n",
    "task_fixb4_c_cond_evs_file = 'fix_b4_c_cond_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_fixb4_c_cond_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_fixb4_c_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_c_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_c_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_c_cond_r4}\\n'])\n",
    "        \n",
    "task_fixb4_ic_cond_evs_file = 'fix_b4_ic_cond_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_fixb4_ic_cond_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_fixb4_ic_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_ic_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_ic_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_ic_cond_r4}\\n'])\n",
    "    \n",
    "task_fixb4_bl_evs_file = 'fix_b4_bl_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_fixb4_bl_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_fixb4_bl_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_bl_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_bl_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_bl_cond_r4}\\n'])\n",
    "\n",
    "task_remain_evs_file = 'events_remain_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_remain_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_remain_evs_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_remain_evs_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_remain_evs_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_remain_evs_cond_r4}\\n'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
