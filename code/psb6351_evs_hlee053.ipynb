{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You first need to set you directory structure\n",
    "# and collect the behavioral files for the localizer and the\n",
    "# study task separately.  Given that each task will be modeled\n",
    "# separately treat them separately.\n",
    "proj_dir = '/home/hlee053/Documents/mattfeld_2020'\n",
    "behav_dir = os.path.join(proj_dir, 'dset', 'sub-021', 'func')\n",
    "loc_behav_files = sorted(glob(behav_dir + '/*loc*.tsv'))\n",
    "study_behav_files = sorted(glob(behav_dir + '/*study*.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'run1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3ef0eab06752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# The following code creates a string element that has the square brackets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# removed.  This is important for the following steps below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mloc_scene_run1_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_scene_onset_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mloc_scene_run2_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_scene_onset_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mloc_face_run1_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_face_onset_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'run1'"
     ]
    }
   ],
   "source": [
    "# In this cell I'm going to first work on the localizer task\n",
    "\n",
    "# Here I am setting up empty dictionary variables that I will\n",
    "# then fill with keys for the different runs which are saved\n",
    "# as separate behavioral tab delimited text files\n",
    "loc_scene_onset_times = {}\n",
    "loc_face_onset_times = {}\n",
    "\n",
    "# Here I am iterating over my text files for the localizer task.\n",
    "# The variable curr_behav_file will be a string variable with\n",
    "# the full path to the separate runs of the localizer task. idx is a counter\n",
    "# used for indexing.\n",
    "for idx, curr_behav_file in enumerate(loc_behav_files):\n",
    "    # Here I am creating my run keys.  idx is 0 based so I am adding a 1.\n",
    "    # The variables associated with each key are empty lists.\n",
    "    loc_scene_onset_times[f'run{idx+1}'] = []\n",
    "    loc_face_onset_times[f'run{idx+1}'] = []\n",
    "    \n",
    "    # I'm using the pandas function read_csv to read in the log files\n",
    "    curr_behav_data = pd.read_csv(curr_behav_file, sep='\\t')\n",
    "    \n",
    "    # I'm creating a temp face and scence onset list variable here because\n",
    "    # the localizer is a block design task.  I want to convolve a hemodynamic\n",
    "    # signal over the entire face and scene periods and not separately for\n",
    "    # each stimulus thus I want to accumulate to onset times for each face/scene\n",
    "    # image presentation and then grab the first.\n",
    "    tmp_face_onset = []\n",
    "    tmp_scene_onset = []\n",
    "    # iterating over trial_type here...i is counter for indexing\n",
    "    \n",
    "    for i, curr_trial_type in enumerate(curr_behav_data['trial_type']):\n",
    "        if curr_trial_type == 'face':\n",
    "            # Here I am appending the onset of the stimulus if the current\n",
    "            # trial type is a face.\n",
    "            tmp_face_onset.append(curr_behav_data['onset'][i])\n",
    "        elif curr_trial_type == 'scence': #note...scence was misspelled originally\n",
    "            # Here I am appending the onset of the stimulus if the current\n",
    "            # trial type is a scene.\n",
    "            tmp_scene_onset.append(curr_behav_data['onset'][i])\n",
    "        # here I am using the first trial type when it becomes math and the \n",
    "        # face onset list variable is 20 elements long (just exited a face block)\n",
    "        # to assign the first element of the tmp_face_onset list variable to the \n",
    "        # dictionary that I created earlier.\n",
    "        elif curr_trial_type == 'math' and len(tmp_face_onset) == 20:\n",
    "            loc_face_onset_times[f'run{idx+1}'].append(f'{tmp_face_onset[0]}:25')\n",
    "            tmp_face_onset = []\n",
    "        elif curr_trial_type == 'math' and len(tmp_scene_onset) == 20:\n",
    "            loc_scene_onset_times[f'run{idx+1}'].append(f'{tmp_scene_onset[0]}:25')\n",
    "            tmp_scene_onset = []\n",
    "            \n",
    "# The following code creates a string element that has the square brackets\n",
    "# removed.  This is important for the following steps below.\n",
    "loc_scene_run1_data = \", \".join(map(str, loc_scene_onset_times['run1']))\n",
    "loc_scene_run2_data = \", \".join(map(str, loc_scene_onset_times['run2']))\n",
    "loc_face_run1_data = \", \".join(map(str, loc_face_onset_times['run1']))\n",
    "loc_face_run2_data = \", \".join(map(str, loc_face_onset_times['run2']))\n",
    "\n",
    "# Here I am defining the sink directory where I would like to save the timing files\n",
    "evs_sink_dir = os.path.join(proj_dir, 'derivatives', 'first_lvl', 'sub-021', 'evs')\n",
    "# I check to see if the directory exists.  If it doesn't I create it.\n",
    "if not os.path.isdir(evs_sink_dir):\n",
    "    os.makedirs(evs_sink_dir)\n",
    "    \n",
    "# below I am defining the file names for the localizer (loc) face and scene evs.\n",
    "# each run is captured on a separate line with the multiple onsets within a run\n",
    "# captured on a single line\n",
    "loc_scene_evs_file = 'loc_scene_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, loc_scene_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{loc_scene_run1_data}\\n'])\n",
    "    fp.writelines([f'{loc_scene_run2_data}\\n'])\n",
    "loc_face_evs_file = 'loc_face_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, loc_face_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{loc_face_run1_data}\\n'])\n",
    "    fp.writelines([f'{loc_face_run2_data}\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to above I am creating empty dictionary variables\n",
    "# for each of the events that I am interested in.\n",
    "# I will then insert run keys to separate the timing files \n",
    "# for the events of interest and their specific runs.\n",
    "task_fixb4_c_cond_onset_times = {}\n",
    "task_fixb4_ic_cond_onset_times = {}\n",
    "task_remain_events_onset_times = {}\n",
    "task_facefixb4_bl_onset_times = {}\n",
    "task_scenefixb4_bl_onset_times = {}\n",
    "\n",
    "# Here I am iterating over the study behavior files.  There should be\n",
    "# 4 of them.\n",
    "for idx, curr_behav_file in enumerate(study_behav_files):\n",
    "    # I set the run key for each condition of interest\n",
    "    task_fixb4_c_cond_onset_times[f'run{idx+1}'] = []\n",
    "    task_fixb4_ic_cond_onset_times[f'run{idx+1}'] = []\n",
    "    task_remain_events_onset_times[f'run{idx+1}'] = []\n",
    "    task_facefixb4_bl_onset_times[f'run{idx+1}'] = []\n",
    "    task_scenefixb4_bl_onset_times[f'run{idx+1}'] = []\n",
    "    \n",
    "    # I read in the current study run behavioral file\n",
    "    curr_behav_data = pd.read_csv(curr_behav_file, sep='\\t')\n",
    "    \n",
    "    # I iterate now over the contents of the run specific data.\n",
    "    # I am specifically iterating over trial_type\n",
    "    for i, curr_trial_type in enumerate(curr_behav_data['trial_type']):\n",
    "        # I am evaluating whether or not the current trail type was a \n",
    "        # fixed association that had a conditional trial that followed with a face\n",
    "        # or a scene\n",
    "        if 'face' in curr_trial_type or 'scene' in curr_trial_type:\n",
    "            # if it was either of those grab that onset\n",
    "            tmp_fix_onset = curr_behav_data['onset'][i]\n",
    "            # if this is not our first trial (i = counter > 0)- remember python is 0-based\n",
    "            if i > 0:\n",
    "                # evaluate whether or not the LAST TRIAL (i-1) was a scene or face fix trial\n",
    "                # grab the current onset time and assign it to the remaining events.\n",
    "                # In the analysis that I am interested in pursuing I want to separate these\n",
    "                # trials from trials where the fix face and scence trials are followed either\n",
    "                # by a conditional trial or by a baseline trial\n",
    "                # I THINK THERE IS A BUG HERE...SEEMING TO ONLY ASSIGN THESE AT THE END OF RUNS\n",
    "                # DEBUG PLEASE\n",
    "                if 'face' in curr_behav_data['trial_type'][i-1] or 'scene' in curr_behav_data['trial_type'][i-1]:\n",
    "                    task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "        # Here I am evaluating whether or not the current trial type is a conditional trial \n",
    "        # that was responded to correctly\n",
    "        elif curr_trial_type == 'COND' and curr_behav_data['acc'][i] == 1.0:\n",
    "            task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "            # I am then evaluating wheter or not the LAST TRIAL (i - 1)...was a fix scence or face\n",
    "            # trial and then appending that temp onset to fill in  \n",
    "            if 'face' in curr_behav_data['trial_type'][i-1] or 'scene' in curr_behav_data['trial_type'][i-1]:\n",
    "                task_fixb4_c_cond_onset_times[f'run{idx+1}'].append(tmp_fix_onset)\n",
    "                # I do the same for conditional trials that were incorrect.  Trying to separate\n",
    "        # fix trials that preceded correct from incorrect conditional trials\n",
    "        elif curr_trial_type == 'COND' and curr_behav_data['acc'][i] == 0.0:\n",
    "            task_remain_events_onset_times[f'run{idx+1}'].append(curr_behav_data['onset'][i])\n",
    "            if 'face' in curr_behav_data['trial_type'][i-1] or 'scene' in curr_behav_data['trial_type'][i-1]:\n",
    "                task_fixb4_ic_cond_onset_times[f'run{idx+1}'].append(tmp_fix_onset)\n",
    "        # Now I am doing the same thing for trials that precede the perceptual baseline trials\n",
    "        # These trials will be used for the MVPA anlaysis that is planned.\n",
    "        # TO DO:  NEED TO SEPARATE THESE FOR SCENCE AND FACE RATHER THAN COMBINE\n",
    "        elif curr_trial_type == 'baseline' and 'face' in curr_behav_data['trial_type'][i-1]:\n",
    "                task_facefixb4_bl_onset_times[f'run{idx+1}'].append(tmp_fix_onset)\n",
    "        elif curr_trial_type == 'baseline' and 'scene' in curr_behav_data['trial_type'][i-1]:\n",
    "                task_scenefixb4_bl_onset_times[f'run{idx+1}'].append(tmp_fix_onset)\n",
    "            \n",
    "# Given that we're setting things up to analyze in AFNI\n",
    "# you can't have runs that don't have any events in them....or\n",
    "# you can but you can't have an empty row...thus here I am checking\n",
    "# to see if the runs are empty and if they are adding a filler (-1)\n",
    "for curr_run in ['run1', 'run2', 'run3', 'run4']:\n",
    "    if len(task_fixb4_c_cond_onset_times[curr_run]) == 0:\n",
    "        task_fixb4_c_cond_onset_times[curr_run].append(-1)\n",
    "    if len(task_fixb4_ic_cond_onset_times[curr_run]) == 0:\n",
    "        task_fixb4_ic_cond_onset_times[curr_run].append(-1)\n",
    "    if len(task_remain_events_onset_times[curr_run]) == 0:\n",
    "        task_remain_events_onset_times[curr_run].append(-1)\n",
    "    if len(task_facefixb4_bl_onset_times[curr_run]) == 0:\n",
    "        task_facefixb4_bl_onset_times[curr_run].append(-1)\n",
    "    if len(task_scenefixb4_bl_onset_times[curr_run]) == 0:\n",
    "        task_scenefixb4_bl_onset_times[curr_run].append(-1)\n",
    "\n",
    "# Reformatting as before to save as a text file with no square brackets\n",
    "task_fixb4_c_cond_r1 = \", \".join(map(str, task_fixb4_c_cond_onset_times['run1']))\n",
    "task_fixb4_c_cond_r2 = \", \".join(map(str, task_fixb4_c_cond_onset_times['run2']))\n",
    "task_fixb4_c_cond_r3 = \", \".join(map(str, task_fixb4_c_cond_onset_times['run3']))\n",
    "task_fixb4_c_cond_r4 = \", \".join(map(str, task_fixb4_c_cond_onset_times['run4']))\n",
    "\n",
    "task_fixb4_ic_cond_r1 = \", \".join(map(str, task_fixb4_ic_cond_onset_times['run1']))\n",
    "task_fixb4_ic_cond_r2 = \", \".join(map(str, task_fixb4_ic_cond_onset_times['run2']))\n",
    "task_fixb4_ic_cond_r3 = \", \".join(map(str, task_fixb4_ic_cond_onset_times['run3']))\n",
    "task_fixb4_ic_cond_r4 = \", \".join(map(str, task_fixb4_ic_cond_onset_times['run4']))\n",
    "\n",
    "task_remain_evs_cond_r1 = \", \".join(map(str, task_remain_events_onset_times['run1']))\n",
    "task_remain_evs_cond_r2 = \", \".join(map(str, task_remain_events_onset_times['run2']))\n",
    "task_remain_evs_cond_r3 = \", \".join(map(str, task_remain_events_onset_times['run3']))\n",
    "task_remain_evs_cond_r4 = \", \".join(map(str, task_remain_events_onset_times['run4']))\n",
    "\n",
    "task_facefixb4_bl_cond_r1 = \", \".join(map(str, task_facefixb4_bl_onset_times['run1']))\n",
    "task_facefixb4_bl_cond_r2 = \", \".join(map(str, task_facefixb4_bl_onset_times['run2']))\n",
    "task_facefixb4_bl_cond_r3 = \", \".join(map(str, task_facefixb4_bl_onset_times['run3']))\n",
    "task_facefixb4_bl_cond_r4 = \", \".join(map(str, task_facefixb4_bl_onset_times['run4']))\n",
    "\n",
    "task_scenefixb4_bl_cond_r1 = \", \".join(map(str, task_scenefixb4_bl_onset_times['run1']))\n",
    "task_scenefixb4_bl_cond_r2 = \", \".join(map(str, task_scenefixb4_bl_onset_times['run2']))\n",
    "task_scenefixb4_bl_cond_r3 = \", \".join(map(str, task_scenefixb4_bl_onset_times['run3']))\n",
    "task_scenefixb4_bl_cond_r4 = \", \".join(map(str, task_scenefixb4_bl_onset_times['run4']))\n",
    "\n",
    "# Creating and checking to see if the directory exists\n",
    "evs_sink_dir = os.path.join(proj_dir, 'derivatives', 'first_lvl', 'sub-021', 'evs')\n",
    "if not os.path.isdir(evs_sink_dir):\n",
    "    os.makedirs(evs_sink_dir)\n",
    "\n",
    "# creating my separate ev files with runs written to each line\n",
    "task_fixb4_c_cond_evs_file = 'fix_b4_c_cond_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_fixb4_c_cond_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_fixb4_c_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_c_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_c_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_c_cond_r4}\\n'])\n",
    "        \n",
    "task_fixb4_ic_cond_evs_file = 'fix_b4_ic_cond_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_fixb4_ic_cond_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_fixb4_ic_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_ic_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_ic_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_fixb4_ic_cond_r4}\\n'])\n",
    "    \n",
    "task_facefixb4_bl_evs_file = 'facefix_b4_bl_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_facefixb4_bl_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_facefixb4_bl_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_facefixb4_bl_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_facefixb4_bl_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_facefixb4_bl_cond_r4}\\n'])\n",
    "    \n",
    "task_scenefixb4_bl_evs_file = 'scenefix_b4_bl_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_scenefixb4_bl_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_scenefixb4_bl_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_scenefixb4_bl_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_scenefixb4_bl_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_scenefixb4_bl_cond_r4}\\n'])\n",
    "\n",
    "task_remain_evs_file = 'events_remain_evs.1D'\n",
    "with open(os.path.join(evs_sink_dir, task_remain_evs_file), 'wt') as fp:\n",
    "    fp.writelines([f'{task_remain_evs_cond_r1}\\n'])\n",
    "    fp.writelines([f'{task_remain_evs_cond_r2}\\n'])\n",
    "    fp.writelines([f'{task_remain_evs_cond_r3}\\n'])\n",
    "    fp.writelines([f'{task_remain_evs_cond_r4}\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is required to run the following 3dDeconvolve calls in the subsequent cells\n",
    "# Here I am collecting the motion related regressor files that were created for each run\n",
    "# separately, concatenating them and saving the output.\n",
    "\n",
    "proj_dir = '/home/hlee053/Documents/mattfeld_2020'\n",
    "motion_dir = '/derivatives/preproc/sub-021/motion'\n",
    "\n",
    "loc_motion_files = sorted(glob(proj_dir + motion_dir + '/*loc*bold.1D'))\n",
    "loc_mot_dict = {}\n",
    "for mot_i, curr_loc_motion_file in enumerate(loc_motion_files):\n",
    "    loc_mot_dict[f'run{mot_i + 1}'] = np.genfromtxt(curr_loc_motion_file)\n",
    "    \n",
    "allruns_loc_motion_data = np.concatenate((loc_mot_dict['run1'], loc_mot_dict['run2']))\n",
    "np.savetxt(proj_dir + motion_dir + '/allruns_loc_mot_data.1D', allruns_loc_motion_data)\n",
    "\n",
    "task_motion_files = sorted(glob(proj_dir + motion_dir + '/*study*bold.1D'))\n",
    "task_mot_dict = {}\n",
    "for mot_i, curr_task_motion_file in enumerate(task_motion_files):\n",
    "    task_mot_dict[f'run{mot_i + 1}'] = np.genfromtxt(curr_task_motion_file)\n",
    "    \n",
    "allruns_task_motion_data = np.concatenate((task_mot_dict['run1'], task_mot_dict['run2'],\n",
    "                                           task_mot_dict['run3'], task_mot_dict['run4']))\n",
    "np.savetxt(proj_dir + motion_dir + '/allruns_task_mot_data.1D', allruns_task_motion_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[7m** FATAL ERROR:\u001b[0m '-stim_times_AM1 1' file '/home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_face_evs.1D' doesn't have any auxiliary values per time point! [nopt=16] :-(\n",
      " ==> You need at least 1 extra value 'married' to each stimulus start time\n",
      "** Program compile date = Aug  4 2020\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'# Given that we are running this with no data (see -nodata flag) we can run a quick bash\\n# command in the cell by using line above.  The matrices that are created and image\\n# will be created in the directory where this jupyter notebook is running. In my case.\\n# /home/data/madlab/Mattfeld_PSB6351/mattfeld_2020/code\\n\\n3dDeconvolve -nodata 608 1.76 \\\\\\n-concat \\'1D: 0 304\\' \\\\\\n-ortvec /home/hlee053/Documents/mattfeld_2020/derivatives/preproc/sub-021/motion/allruns_loc_mot_data.1D motion \\\\\\n-polort A \\\\\\n-local_times \\\\\\n-num_stimts 2 \\\\\\n-stim_times_AM1 1 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_face_evs.1D \"dmBLOCK(1)\" -stim_label 1 faces \\\\\\n-stim_times_AM1 2 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_scene_evs.1D \"dmBLOCK(1)\" -stim_label 2 scenes \\\\\\n-x1D X.loc.xmat.1D -xjpeg X.loc.jpg\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8056a341a3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# Given that we are running this with no data (see -nodata flag) we can run a quick bash\\n# command in the cell by using line above.  The matrices that are created and image\\n# will be created in the directory where this jupyter notebook is running. In my case.\\n# /home/data/madlab/Mattfeld_PSB6351/mattfeld_2020/code\\n\\n3dDeconvolve -nodata 608 1.76 \\\\\\n-concat \\'1D: 0 304\\' \\\\\\n-ortvec /home/hlee053/Documents/mattfeld_2020/derivatives/preproc/sub-021/motion/allruns_loc_mot_data.1D motion \\\\\\n-polort A \\\\\\n-local_times \\\\\\n-num_stimts 2 \\\\\\n-stim_times_AM1 1 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_face_evs.1D \"dmBLOCK(1)\" -stim_label 1 faces \\\\\\n-stim_times_AM1 2 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_scene_evs.1D \"dmBLOCK(1)\" -stim_label 2 scenes \\\\\\n-x1D X.loc.xmat.1D -xjpeg X.loc.jpg\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/psb6351_environment/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/psb6351_environment/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/psb6351_environment/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/psb6351_environment/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'# Given that we are running this with no data (see -nodata flag) we can run a quick bash\\n# command in the cell by using line above.  The matrices that are created and image\\n# will be created in the directory where this jupyter notebook is running. In my case.\\n# /home/data/madlab/Mattfeld_PSB6351/mattfeld_2020/code\\n\\n3dDeconvolve -nodata 608 1.76 \\\\\\n-concat \\'1D: 0 304\\' \\\\\\n-ortvec /home/hlee053/Documents/mattfeld_2020/derivatives/preproc/sub-021/motion/allruns_loc_mot_data.1D motion \\\\\\n-polort A \\\\\\n-local_times \\\\\\n-num_stimts 2 \\\\\\n-stim_times_AM1 1 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_face_evs.1D \"dmBLOCK(1)\" -stim_label 1 faces \\\\\\n-stim_times_AM1 2 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_scene_evs.1D \"dmBLOCK(1)\" -stim_label 2 scenes \\\\\\n-x1D X.loc.xmat.1D -xjpeg X.loc.jpg\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Given that we are running this with no data (see -nodata flag) we can run a quick bash\n",
    "# command in the cell by using line above.  The matrices that are created and image\n",
    "# will be created in the directory where this jupyter notebook is running. In my case.\n",
    "# /home/data/madlab/Mattfeld_PSB6351/mattfeld_2020/code\n",
    "\n",
    "3dDeconvolve -nodata 608 1.76 \\\n",
    "-concat '1D: 0 304' \\\n",
    "-ortvec /home/hlee053/Documents/mattfeld_2020/derivatives/preproc/sub-021/motion/allruns_loc_mot_data.1D motion \\\n",
    "-polort A \\\n",
    "-local_times \\\n",
    "-num_stimts 2 \\\n",
    "-stim_times_AM1 1 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_face_evs.1D \"dmBLOCK(1)\" -stim_label 1 faces \\\n",
    "-stim_times_AM1 2 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/loc_scene_evs.1D \"dmBLOCK(1)\" -stim_label 2 scenes \\\n",
    "-x1D X.loc.xmat.1D -xjpeg X.loc.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "3dDeconvolve -nodata 1420 1.76 \\\n",
    "-concat '1D: 0 355 710 1065' \\\n",
    "-ortvec /home/hlee053/Documents/mattfeld_2020/derivatives/preproc/sub-021/motion/allruns_task_mot_data.1D motion \\\n",
    "-polort A \\\n",
    "-local_times \\\n",
    "-num_stimts 5 \\\n",
    "-stim_times 1 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/fix_b4_c_cond_evs.1D \"TWOGAMpw(4,5,0.2,12,7)\" -stim_label 1 fx_b4_c_cond \\\n",
    "-stim_times 2 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/fix_b4_ic_cond_evs.1D \"TWOGAMpw(4,5,0.2,12,7)\" -stim_label 2 fx_b4_ic_cond \\\n",
    "-stim_times 3 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/events_remain_evs.1D \"TWOGAMpw(4,5,0.2,12,7)\" -stim_label 3 all_remain \\\n",
    "-stim_times 4 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/facefix_b4_bl_evs.1D \"TWOGAMpw(4,5,0.2,12,7)\" -stim_label 4 facefx_b4_bl \\\n",
    "-stim_times 5 /home/hlee053/Documents/mattfeld_2020/derivatives/first_lvl/sub-021/evs/scenefix_b4_bl_evs.1D \"TWOGAMpw(4,5,0.2,12,7)\" -stim_label 5 scenefx_b4_bl \\\n",
    "-x1D X.task.xmat.1D -xjpeg X.task.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_task = Image.open(os.path.join(os.getcwd(), 'X.task.jpg'))\n",
    "im_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_loc = Image.open(os.path.join(os.getcwd(), 'X.loc.jpg'))\n",
    "im_loc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
