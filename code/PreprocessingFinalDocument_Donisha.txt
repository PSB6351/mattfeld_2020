Participant 

The self-volunteered, single-subject (n = 1) was a right-handed , 42-year-old, Caucasian male, with corrected vision, and prior experience with fMRI scanning protocols, scanning session, and within-scanner tasks involving distinguishing between two stimuli types. Additionally, medical information stating whether or not the subject has been diagnosed with any psychopathologies or neurodegenerative disorders, which could affect task performance, prior to the scanning session was unknown. 

Localizer Task

Study - Event-Related

The localizer task consisted of a block design where the subject was shown presentation blocks of faces, scenes, and simple mathematical inequality problems requesting the subject to indicate if a number was less than or greater than five. Each block lasted for approximately 25 seconds and were preceded  by an inter-stimulus interval lasting for a few seconds and included a screen with a white fixation cross. During the study phase, which had an event-related design and was composed of four fixed trials and one conditional trial, the subject was instructed to associate a kaleidoscopic image with a particular image through trial and error. For fixed trials, the subject was presented with a series of four unique kaleidoscopic shapes accompanied with images of objects on the left and right of the screen (which also swapped their locations with one another on subsequent trials). After a second, the kaleidoscopic image disappeared and the subject was prompted to select the left or right image on their response pad. Immediately after, the subject was provided with on-screen feedback informing them on the accuracy of their selection. For conditional trials, the participant were forewarned that the fifth presentation screen, which possessed a kaleidoscopic image accompanied by a picture of a face and object on the left and right of the screen, was conditional on the preceding image and was shown the correct associations during the instruction phase. Additionally, only fixed presentation trials were preceded by an inter-stimulus interval where the subject was shown a screen with a white fixation cross. 


Neuro-imaging and Preprocessing

The scanning session was conducted at the Center for Imaging Science located at Florida International and the subject’s neuro-imaging data was collected with a 32 -channel head coil on a 3T Siemens MAGNETOM Prisma scanner. Two runs of T1-weighted scans were conducted using an inversion recovery gradient echo scanning sequence using the parameters: Inversion Time = 1.07s,  TR = 2.5s, TE = 0.0029s, Flip Angle = 8.0 degrees, FOV = 256,  voxel = 1mm isotropic, and 176 axial slices. Additionally, T2-weighted images were collected during the functional runs, which consisted of two localizer sessions and four study runs using echo planner sequences using the parameters: TR = 1.76s, TE = 0.035s, Flip Angle = 52 degrees, FOV = 90, Multiband Acceleration Factor = 3, voxel = 2mm isotropic, and 66 sagittal slices. Finally, 304 whole brain volumes were gathered during each localizer run and 355 whole brain volumes were obtained during each study run. 

Prior to preprocessing, the subject’s DICOM data was converted into BIDS format using templates and code available from HeuDiConv (version 0.8.0;  Kennedy et al., 2019). Preprocessing of the subject’s neuro-imaging data was conducted using functions and wrappers available in Nipype (Nipype version 1.5.1; Gorgolewski et al., 2011). The percentage of voxels considered outliers was calculated with AFNI’s 3dToutcount (AFNI version 20.2.06; Cox, 1996) and graphically visualized and inspected using plotting functions available from Numpy  (NumPy version  1.19.2; Harris et al., 2020). After, 3dDespiking (AFNI version 20.2.06; Cox, 1996) was used to generate a new dataset using an algorithm that interpolates over outliers on a voxelwise basis; thus, reducing the influence these outliers have on subsequent data analysis and improving the efficiency of further preprocessing steps such as motion correction and registration. Motion correction was conducted using MCFLIRT  (FSL version 5.0.11; Jenkinson et al., 2012) specifying a mutual information interpolation paired with a sinc cost function. The reference image used for MCFLIRT and registered in Freesurfer space using BBRegister (Freesurfer version 6.0; Fischl et al., 1999) was derived using OutlierCount (AFNI version 20.2.06; Cox, 1996) to determine the volume with the least outliers and extractROI (FSL version 5.0.11; Smith et al.,  2004)  to extract this reference volume. After, TShift (AFNI version 20.2.06; Cox, 1996) was used with ‘quintic’ interpolation and a TR of 1.76s for slice timing correction. Additionally, skull stripping was done by using FreeSurferSource and Binarize (Freesurfer version 6.0; Fischl et al., 1999) functions to binarize and create a dilated mask by one voxel in Freesurfer Space. Then subject-to-subject volume registration was done with the ApplyVolTransform  Freesurfer version 6.0; Fischl et al., 1999) function using a nearest neighbor interpolation to apply the reference image to both the binarized mask and Freesurfer template. Finally, the transformed reference image was applied to the rest of the dataset to complete the skull stripping. Smoothing was conducted using SUSAN (FSL version 5.0.11; Smith & Brady, 1997) algorithm,  ‘usans’ was defined as the merged image (using the util.Merge function which axis defined as ‘hstack’) of  ImageMaths (FSL version 5.0.11; Smith et al.,  2004) using the parameter op_string = ‘-Tmean’ to create a mean functional image and another ImageMaths node using the parameters '-k %s -p 50’. Additionally, the brightness threshold was defined as 75% of medium value for each run, and the FWHM as a list of containing the values, 2.0, 4.0, 6.0, 8.0, 10.0,  and 12.0. Finally, ArtifactDetect (Nipype version 1.5.1; Gorgolewski et al., 2011)  function with norm threshold and z intensity set at 1 and 3, respectively, was used to obtain the number of outliers for further data analysis. 

MRI Data Analysis

Model

To analyze  whole brain response during each stimulus presentation, AFNI’s 3dDeconvolve (AFNI version 20.2.06; Cox, 1996)  was used to generate a general linear regression matrix  specifying the the regressors of interest as onset times of each stimuli presentation and the regressors of no interest as motion regressors and additional artifact regressors for both localizer and study runs. For the localizer tasks, the parameters used in 3dDeconvolve to construct the design matrix for all localizer runs specified that the contrasting stimuli were ‘face’ and ‘scene’ , included the onset time for each stimuli, and indicated the response model as blocked response model = dmBLOCK) Each run was specified to have 304 timepoints for a total of 608 timepoints with a TR of 1.76; however; since ArtifactDetect flagged the first and second timepoints for both runs as outliers, the first and second time points were censored thus reducing the total timepoints to 604. Additionally, the design matrix for all study tasks specified the contrasts as ‘ fix_b4_c_cond_evs’, ‘fix_b4_ic_cond_evs’, ‘events_remain_evs’, ‘facefix_b4_bl_evs’, ‘scenefix_b4_bl_evs’ - five event-related stimuli, each with 355 timepoints resulting in a combined total of 1420 timepoints and a TR of 1.76 - and the onset times of each five stimuli.  The response model  for all stimuli were specified as TWOGAMpw with K1 = 4, W1 = 5, r = 0.2, K2 = 12 , W2 = 7 and. For the study runs, ArtfactDectect flagged timepoints 0-1 as outliers for all study runs, timepoints 2 as an outlier in study run 2, and timepoints 201 as an outlier in study run 4, thus these timepoints were censored using  the ‘CENSORTR’ parameter, the ‘polort’ parameter was set to automatic, and motion regressors were specified using ‘ortvec . Finally, for both the task and study design matrices the ‘polort’ parameter was set to automatic, and motion regressors were specified using ‘ortvec’.



Cox, R. W. (1996). AFNI: Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages. Computers and Biomedical Research, 29(3), 162–173. https://doi.org/10.1006/cbmr.1996.0014

Fischl, B., Sereno, M. I., & Dale, A. M. (1999). Cortical Surface-Based Analysis. NeuroImage, 9(2), 195–207. https://doi.org/10.1006/nimg.1998.0396


Kennedy, D. N., Abraham, S. A., Bates, J. F., Crowley, A., Ghosh, S., Gillespie, T., Goncalves, M., Grethe, J. S., Halchenko, Y. O., Hanke, M., Haselgrove, C., Hodge, S. M., Jarecka, D., Kaczmarzyk, J., Keator, D. B., Meyer, K., Martone, M. E., Padhy, S., Poline, J.-B., … Travers, M. (2019). Everything Matters: The ReproNim Perspective on Reproducible Neuroimaging. Frontiers in Neuroinformatics, 13, 1–10. https://doi.org/10.3389/fninf.2019.00001

Gorgolewski, K., Burns, C. D., Madison, C., Clark, D., Halchenko, Y. O., Waskom, M. L., & Ghosh, S. S. (2011). Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python. Frontiers in Neuroinformatics, 5, 1–10. https://doi.org/10.3389/fninf.2011.00013

Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., del Río, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy. Nature, 585(7825), 357–362. https://doi.org/10.1038/s41586-020-2649-2


Jenkinson, M., Bannister, P., Brady, M., & Smith, S. (2002). Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images. NeuroImage, 17(2), 825–841. https://doi.org/10.1006/nimg.2002.1132


Smith, S. M., Jenkinson, M., Woolrich, M. W., Beckmann, C. F., Behrens, T. E. J., Johansen-Berg, H., Bannister, P. R., De Luca, M., Drobnjak, I., Flitney, D. E., Niazy, R. K., Saunders, J., Vickers, J., Zhang, Y., De Stefano, N., Brady, J. M., & Matthews, P. M. (2004). Advances in functional and structural MR image analysis and implementation as FSL. NeuroImage, 23, S208–S219. https://doi.org/10.1016/j.neuroimage.2004.07.051

Smith, S. M., & Brady, J. M. (1997). SUSAN—A New Approach to Low Level Image Processing. International Journal of Computer Vision, 23(1), 45–78. https://doi.org/10.1023/a:1007963824710

