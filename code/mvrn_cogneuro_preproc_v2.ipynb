{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Import new things that we'll need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nipype.interfaces.afni as afni\n",
    "import nipype.interfaces.fsl as fsl\n",
    "from nipype.interfaces.utility import Function\n",
    "import seaborn as sns\n",
    "import nibabel as nb\n",
    "import json\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.pipeline.engine as pe \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sid = ['021']\n",
    "base_dir = '/home/mrive301/Documents/CogNeuro_Methods/CogNeuro_proj'\n",
    "work_dir = '/scratch/madlab/mvrn_cogneuro'\n",
    "\n",
    "#Creating a function to iterate over all tasks in functional directory\n",
    "def task_iterate(func_scan):\n",
    "    files = os.path.join(base_dir, f'dset/sub-{sid[0]}/{func_scan}')\n",
    "    for file in files:\n",
    "        get_loc_json = sorted(glob(files + '/*localizer*.json')) \n",
    "        get_loc_nii = sorted(glob(files + '/*localizer*.nii.gz'))\n",
    "        get_task_json = sorted(glob(files + '/*task-*.json'))\n",
    "        get_task_nii = sorted(glob(files + '/*task-*.nii.gz'))\n",
    "        #I could add other tasks to this list, if the func directory had more\n",
    "        return get_loc_json, get_loc_nii, get_task_json, get_task_nii\n",
    "\n",
    "#Returning all of the functional files\n",
    "functional = task_iterate(\"func\")\n",
    "\n",
    "#Getting the functional json files\n",
    "study_func_json = functional[2:3]\n",
    "\n",
    "#Returning the functional nifty files\n",
    "study_func_files = functional[3:]\n",
    "\n",
    "'''\n",
    "========================================================\n",
    "Creating function to eliminate mapnode directory structure \n",
    "and saving output func_filed in a dingle directory\n",
    "========================================================\n",
    "'''\n",
    "def get_subs(func_files):\n",
    "    '''Produces Name Substitutions for Each Contrast'''\n",
    "    subs = []\n",
    "    for curr_run in range(len(func_files)):\n",
    "        subs.append(('_tshifter%d' %curr_run, ''))\n",
    "        subs.append(('_volreg%d' %curr_run, ''))\n",
    "    return subs\n",
    "\n",
    "'''\n",
    "========================================================\n",
    "Receiving text file with number of outliers per volume. Then,\n",
    "we find which volume index has the least number of outliers.\n",
    "\n",
    "We search over the first 201 volumes.\n",
    "\n",
    "If index returns list, that's becaus there were multiple\n",
    "volumes wih the same number of outliers. If so, we pick the \n",
    "first one.\n",
    "========================================================\n",
    "'''\n",
    "\n",
    "def best_vol(outlier_count):\n",
    "    #Searching over 201 volumes which one has the least number of \n",
    "        #outliers. If best one found, we return such one. \n",
    "    best_vol_num = outlier_count.index(min(outlier_count[:200]))\n",
    "    #If not, and all have same number of outliers, we return first one\n",
    "    if isinstance(best_vol_num, list):\n",
    "        best_vol_num = best_vol_num[0]\n",
    "    return best_vol_num\n",
    "\n",
    "'''\n",
    "========================================================\n",
    "Creating list with ST for each study run\n",
    "========================================================\n",
    "'''\n",
    "slice_timing_list = []\n",
    "for curr_json in study_func_json:\n",
    "    curr_json_data = open(curr_json) #opening json with func data\n",
    "    curr_study_func_metadata = json.load(curr_json_data) #loading json files\n",
    "    #Appending functional json ST files\n",
    "    slice_timing_list.append(curr_study_func_metadata['SliceTiming'])\n",
    "\n",
    "# Establishing a nipype work flow that will eventually be executed\n",
    "cogneuro_wf = pe.Workflow(name='cogneuro_wf')\n",
    "\n",
    "'''\n",
    "========================================================\n",
    "The following contributes to the function above that \n",
    "eliminates the mapnode by substituting the \"func_files\" \n",
    "name with \"subs\". \n",
    "========================================================\n",
    "'''\n",
    "# Create a Function node to substitute names of files created during pipeline\n",
    "#Based on first function created int this cell\n",
    "getsubs = pe.Node(Function(input_names=['func_files'],\n",
    "                                             output_names=['subs'],\n",
    "                                             function=get_subs),\n",
    "                              name='getsubs')\n",
    "getsubs.inputs.func_files = study_func_files\n",
    "\n",
    "'''\n",
    "========================================================\n",
    "Using 3dToutcount to find the number of outliers per vol.\n",
    "This is allowing us to create our basis for motion correction\n",
    "by selecting the first volume with the lowest outlier number.\n",
    "========================================================\n",
    "'''\n",
    "id_outliers = pe.Node(afni.OutlierCount(),\n",
    "                      name = 'id_outliers')\n",
    "#Trying another volume...closer to where the functional\n",
    "#localizer to see what would happen...\n",
    "id_outliers.inputs.in_file = study_func_files[7]\n",
    "id_outliers.inputs.automask = True\n",
    "id_outliers.inputs.out_file = 'outlier_file'\n",
    "\n",
    "'''\n",
    "========================================================\n",
    "Passig the node that will allow us to get the best volume (the\n",
    "one with the min number of outliers). This is based on \n",
    "previous outlier function above.\n",
    "========================================================\n",
    "'''\n",
    "getbestvol = pe.Node(Function(input_names=['outlier_count'],\n",
    "                                  output_names=['best_vol_num'],\n",
    "                                  function=best_vol),\n",
    "                                   name='getbestvol')\n",
    "cogneuro_wf.connect(id_outliers, 'out_file', getbestvol, 'outlier_count')\n",
    "\n",
    "'''\n",
    "=========================================================\n",
    "Extracting middle-ish volume of the first run as our reference\n",
    "image.\n",
    "=========================================================\n",
    "'''\n",
    "extractref = pe.Node(fsl.ExtractROI(t_size=1),\n",
    "                     name = \"extractref\")\n",
    "extractref.inputs.in_file = study_func_files[7]\n",
    "#extractref.inputs.t_min = int(np.ceil(nb.load(study_func_files[0]).shape[3]/2)) #PICKING MIDDLE\n",
    "cogneuro_wf.connect(getbestvol, 'best_vol_num', extractref, 't_min')\n",
    "\n",
    "'''\n",
    "=============================================================\n",
    "Aaron's question: Would I want to do slice timing correction here?\n",
    "Why? Why not?\n",
    "Answer: No, you want to do so after motion correction, otherwise \n",
    "you may have motion intensity differences propagated across time.\n",
    "=============================================================\n",
    "'''\n",
    "\n",
    "'''\n",
    "=============================================================\n",
    "Running AFNI's 3dvolreg for motion correction. We iterate over\n",
    "our functional files which we pass functional data from the\n",
    "slice timing correction node before we use the earliest volume with\n",
    "the least number of outliers during the first run\n",
    "as the base file to register to.\n",
    "=============================================================\n",
    "'''\n",
    "'''\n",
    "volreg = pe.MapNode(afni.Volreg(),\n",
    "                    iterfield=['in_file'],\n",
    "                    name = 'volreg')\n",
    "volreg.inputs.outputtype = 'NIFTI_GZ'\n",
    "volreg.inputs.zpad = 4\n",
    "cogneuro_wf.connect(tshifter, 'out_file', volreg, 'in_file')\n",
    "cogneuro_wf.connect(extractref, 'roi_file', volreg, 'basefile')\n",
    "\n",
    "# Below is the code if I wanted to use the FSL McFlirt command\n",
    "'''\n",
    "motion_corr = pe.MapNode(fsl.MCFLIRT(),\n",
    "                         iterfield=['in_file'],\n",
    "                         name = 'motion_corr')\n",
    "motion_corr.inputs.output_type = 'NIFTI_GZ'\n",
    "\n",
    "'''\n",
    "=============================================================\n",
    "Running AFNIs 3dTshift to do ST correction. We input the \n",
    "functional files as a list, along with the ST as a list of lists. We\n",
    "use a mapnode to iterate over the two so we can run them\n",
    "at the same time on the HPC.\n",
    "=============================================================\n",
    "'''\n",
    "\n",
    "tshifter = pe.MapNode(afni.TShift(),\n",
    "                      iterfield=['in_file','slice_timing'],\n",
    "                      name = 'tshifter')\n",
    "tshifter.inputs.in_file = study_func_files\n",
    "tshifter.inputs.tr = str(curr_study_func_metadata['RepetitionTime'])\n",
    "tshifter.inputs.slice_timing = slice_timing_list\n",
    "#Reversing slice timing\n",
    "tshift.inputs.slice_encoding_direction = 'k-'\n",
    "#Changing interpolation to linear (default = Fourier)\n",
    "tshift.inputs.interp = 'linear'\n",
    "tshifter.inputs.outputtype = 'NIFTI_GZ'\n",
    "cogneuro_wf.connect(motion_corr, 'out_file', tshifter, 'in_file')\n",
    "cogneuro_wf.connect(extractref, 'roi_file', tshifter, 'ref_file')\n",
    "\n",
    "'''\n",
    "=============================================================\n",
    "Sinking data!\n",
    "=============================================================\n",
    "'''\n",
    "datasink = pe.Node(nio.DataSink(), name=\"datasink\")\n",
    "datasink.inputs.base_directory = os.path.join(base_dir, 'derivatives')\n",
    "datasink.inputs.container = f'sub-{sid[0]}'\n",
    "cogneuro_wf.connect(tshifter, 'out_file', datasink, 'sltime_corr')\n",
    "cogneuro_wf.connect(extractref, 'roi_file', datasink, 'study_ref')\n",
    "cogneuro_wf.connect(volreg, 'out_file', datasink, 'motion.@corrfile')\n",
    "cogneuro_wf.connect(volreg, 'oned_matrix_save', datasink, 'motion.@matrix')\n",
    "cogneuro_wf.connect(volreg, 'oned_file', datasink, 'motion.@par')\n",
    "cogneuro_wf.connect(getsubs, 'subs', datasink, 'substitutions')\n",
    "\n",
    "# The following two lines set a work directory outside of my \n",
    "# local git repo and runs the workflow\n",
    "cogneuro_wf.base_dir = work_dir + f'/cogneuroworkdir_v2/sub-{sid[0]}'\n",
    "cogneuro_wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
